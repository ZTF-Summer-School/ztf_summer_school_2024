{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning for Time Domain Astronomy\n",
    "ZTF Summer School 2023\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First, please visit the ZTF website at: https://ztf.caltech.edu to learn understand what exciting science is being done with ZTF data!**\n",
    "\n",
    "\n",
    "Requirements:\n",
    "- Matrix Convolution/Kernel operations: https://en.wikipedia.org/wiki/Kernel_(image_processing)\n",
    "- Neural Networks/Perceptron: http://neuralnetworksanddeeplearning.com/chap1.html#perceptrons\n",
    "- Convolutional Neural Networks (CNN): http://neuralnetworksanddeeplearning.com/chap6.html#introducing_convolutional_networks\n",
    "- Tensorflow and Keras, which we'll use to create the models and train them: https://www.tensorflow.org/tutorials/keras/classification\n",
    "- ZTF alerts: https://www.ztf.caltech.edu/ztf-alert-stream.html and https://iopscience.iop.org/article/10.1088/1538-3873/aae904/pdf\n",
    "\n",
    "Optional, but recommended:\n",
    "- Weights and Biases Quickstart: https://docs.wandb.ai/quickstart (you will need to create an account anyway!)\n",
    "- Early stopping: https://en.wikipedia.org/wiki/Early_stopping\n",
    "- Dropout: https://en.wikipedia.org/wiki/Dilution_(neural_networks)\n",
    "- Plateau phenomenon: https://analyticsindiamag.com/what-is-the-plateau-problem-in-neural-networks-and-how-to-fix-it\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overview:\n",
    "\n",
    "We'll have a look at how the alert scanning process can be automatized (or at least facilitated) by teaching neural networks how to look at the cutouts and metadata from the alert packets just like humans would. We'll talk about the model's architecture, how to train it, evaluate it, and how to fine-tune it with the help of wandb.ai.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Requirements:\n",
    "1. Python 3.8 or later\n",
    "2. Simply install the requirements with `pip install -r requirements.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# but of course, let's start with the imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import wandb\n",
    "from ast import literal_eval\n",
    "import scipy\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout, Concatenate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Downloading the dataset:\n",
    "1. Go to https://drive.usercontent.google.com/download?id=16ufsYYbpJ0ZWw2ZIibPfQQ81k7OBNl9Z&export=download&authuser=0\n",
    "2. Place the downloaded ZIP file in the same directory as this notebook\n",
    "3. Unzip the file, and you're ready to go!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick reminder: Convolutional Neural Network (CNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"In deep learning, a convolutional neural network (CNN) is a class of artificial neural network most commonly applied to analyze visual imagery.[1] CNNs use a mathematical operation called convolution in place of general matrix multiplication in at least one of their layers.[2] They are specifically designed to process pixel data and are used in image recognition and processing.\"\n",
    "*https://en.wikipedia.org/wiki/Convolutional_neural_network*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://miro.medium.com/v2/resize:fit:1162/format:webp/1*tvwYybdIwvoOs0DuUEJJTg.png\" alt=\"Drawing\" style=\"width: 800px;\"/>\n",
    "<p style=\"font-size: 10px;\">Source: https://medium.com/techiepedia/binary-image-classifier-cnn-using-tensorflow-a3f5d6746697</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A basic CNN is composed of several layers:\n",
    "- Convolutional layers: they apply a convolution operation to the input, passing the result to the next layer.\n",
    "- Pooling layers: they downsample the input along the spatial dimensions (width, height), reducing the number of parameters and computation in the network.\n",
    "- Fully connected layers: they compute the class scores, resulting in a vector of size equal to the number of classes. If the classification we expect is binary (simply True if >0.5, otherwise False), the last layer is a single neuron with a sigmoid activation function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input can be either a single image, composed of one or more channels (e.g. RGB), or a batch of images of the same size. When it comes to the cutouts found in the ZTF alert packets, they are a set of 3 images (science, template, difference) of size 63x63 pixels, each with 1 channel (grayscale). Meaning the imput is of size (63, 63, 3)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./alert_cutouts.png\" alt=\"Drawing\" style=\"width: 800px;\"/>\n",
    "<p style=\"font-size: 10px;\">Screenshot (from fritz.science) of the cutouts from the latest alert for ZTF23aaqqfac</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What about metadata?\n",
    "\n",
    "Often, the data available isn't just one or more image, but also metadata that was computed which can be used to improve the classification. For example, the metadata can be the position of the object, the time of the observation, the magnitude of the object, etc. The metadata can be used in two ways:\n",
    "- As an additional input to the CNN, concatenated to the image.\n",
    "- As an additional input to the CNN, concatenated to the output of the last convolutional layer.\n",
    "\n",
    "Later in this notebook, you'll see that the process of \"merging\" the CNN model and the metadata (which is a classic neural network) model into one is extremely simple.\n",
    "\n",
    "The metadata goes through its own set of fully connected layers, and the output is concatenated to the output of the last convolutional layer after it has been flattened. The resulting vector is then fed to the fully connected layers that later compute the class scores. The BTS model aims to predict one thing: the probability that the object is a bright transient, of interest for the Bright Transient Survey (BTS) group.\n",
    "\n",
    "<img src=\"http://neuralnetworksanddeeplearning.com/images/tikz11.png\" alt=\"Drawing\" style=\"width: 800px; background-color: white;\"/>\n",
    "<p style=\"font-size: 10px;\">Basic neural network with 2 hidden layers, with one neuron as an ouput to perform binary classification. Just like the one our alert metadata will go through. Source: http://neuralnetworksanddeeplearning.com/chap1.html</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### But why do we need AI for any of this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa327668d-b172-44e7-a2b0-4671c235ce79_682x500.jpeg\" alt=\"Drawing\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"The Bright Transient Survey (BTS) relies on visual inspection (“scanning”) to select sources\n",
    "for accomplishing its mission of spectroscopically classifying all bright extragalactic transients\n",
    "found by the Zwicky Transient Facility (ZTF).\n",
    "We present BTSbot, a multi-input convolutional\n",
    "neural network, which provides a bright transient\n",
    "score to individual ZTF detections using their image data and 14 extracted features. BTSbot eliminates the need for scanning by automatically identifying and requesting follow-up observations of\n",
    "new bright (magpsf < 18.5 mag) transient candidates.\n",
    "In validation, BTSbot outperforms BTS scanners in terms of completeness (99% vs. 95%) and\n",
    "identification speed (on average, 7.4 h quicker).\"\n",
    "\n",
    "Source: Nabeel Rehemtulla, BTSbot's creator :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To summarize: Instead of relying on people to look at thousands of alerts every day to find which ones are worth getting a spectrum for, we train a model to do it for us. Just like a person scanning, the model can look at both images and metadata, except more consistently and orders of magnitude faster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BTS model\n",
    "\n",
    "As mentioned earlier, the model comprises two parts: the CNN and the metadata part, merged to yield one output. Here is what it looks like:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architecture:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN model:\n",
    "- 2 blocks of 2 convolutional layers, each followed by a pooling layer, and a dropout layer.\n",
    "- a flatten layer.\n",
    "\n",
    "Metadata model:\n",
    "- 2 fully connected layers.\n",
    "\n",
    "Merged model:\n",
    "- the output of the flatten layer of the CNN model is concatenated to the output of the metadata model.\n",
    "- Followed by one fully connected layer, a dropout layer, and the output layer (a single neuron with a sigmoid activation function).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we define some basic constants.\n",
    "config = {\n",
    "    'image_size': (63,63,3),\n",
    "    'metadata_size': (14,),\n",
    "    'dropout_1': 0.3,\n",
    "    'dropout_2': 0.3,\n",
    "    'dropout_3': 0.3,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we prepare the input layers\n",
    "triplet_input = keras.Input(shape=config[\"image_size\"], name='triplet')\n",
    "meta_input = keras.Input(shape=config[\"metadata_size\"], name='metadata')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN part of the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first conv block\n",
    "x_conv = Conv2D(16, (3, 3), activation='relu', padding='same', input_shape=(63, 63, 3), name='conv1')(triplet_input)\n",
    "x_conv = Conv2D(16, (3, 3), activation='relu', padding='same', name='conv2')(x_conv)\n",
    "x_conv = MaxPooling2D(pool_size=(2, 2), name='pool1')(x_conv)\n",
    "x_conv = Dropout(config[\"dropout_1\"], name='drop1')(x_conv)\n",
    "\n",
    "# second conv block\n",
    "x_conv = Conv2D(32, (3, 3), activation='relu', padding='same', name='conv3')(x_conv)\n",
    "x_conv = Conv2D(32, (3, 3), activation='relu', padding='same', name='conv4')(x_conv)\n",
    "x_conv = MaxPooling2D(pool_size=(4, 4), name='pool2')(x_conv)\n",
    "x_conv = Dropout(config[\"dropout_2\"], name='drop2')(x_conv)\n",
    "\n",
    "# we flatten the output\n",
    "x_conv = Flatten()(x_conv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metadata part of the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metadata model\n",
    "x_meta = Dense(16, activation='relu', name='metadata_fc_1')(meta_input)\n",
    "x_meta = Dense(32, activation='relu', name='metadata_fc_2')(x_meta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting it all together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merged model\n",
    "x = Concatenate(axis=1)([x_conv, x_meta])\n",
    "x = Dense(16, activation='relu', name='comb_fc_2')(x)\n",
    "x = Dropout(config[\"dropout_3\"])(x)\n",
    "\n",
    "# Output (binary classification, a single sigmoid neuron giving us a score between 0 (not BTS) and 1 (BTS!!!))\n",
    "output = Dense(1, activation='sigmoid', name='fc_out')(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compile the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Model(inputs=[triplet_input, meta_input], outputs=output, name=\"mi_cnn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the model with a graph:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./model.png\" alt=\"Drawing\" style=\"width: 500px;\"/>\n",
    "\n",
    "Easy, right? :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's just test it on a fake input, to verify that the model is working as expected (all the layers are connected correctly, the inputs and outputs has the right shape, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 69ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.5]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_triplet = np.zeros((1, 63, 63, 3))\n",
    "fake_meta = np.zeros((1, 14))\n",
    "\n",
    "model.predict([fake_triplet, fake_meta])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's just refactor all this to have a nice method to instantiate a model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BTSModel(config):\n",
    "    #image size and metadata size might be strings, so we convert them to tuples with a literal eval\n",
    "    if type(config[\"image_size\"]) == str:\n",
    "        image_size = literal_eval(config[\"image_size\"])\n",
    "    else:\n",
    "        image_size = config[\"image_size\"]\n",
    "    if type(config[\"metadata_size\"]) == str:\n",
    "        metadata_size = literal_eval(config[\"metadata_size\"])\n",
    "    else:\n",
    "        metadata_size = config[\"metadata_size\"]\n",
    "\n",
    "    # first we prepare the input layers\n",
    "    triplet_input = keras.Input(shape=image_size, name='triplet')\n",
    "    meta_input = keras.Input(shape=metadata_size, name='metadata')\n",
    "\n",
    "    # first conv block\n",
    "    x_conv = Conv2D(16, (3, 3), activation='relu', padding='same', input_shape=(63, 63, 3), name='conv1')(triplet_input)\n",
    "    x_conv = Conv2D(16, (3, 3), activation='relu', padding='same', name='conv2')(x_conv)\n",
    "    x_conv = MaxPooling2D(pool_size=(2, 2), name='pool1')(x_conv)\n",
    "    x_conv = Dropout(config[\"dropout_1\"], name='drop1')(x_conv)\n",
    "\n",
    "    # second conv block\n",
    "    x_conv = Conv2D(32, (3, 3), activation='relu', padding='same', name='conv3')(x_conv)\n",
    "    x_conv = Conv2D(32, (3, 3), activation='relu', padding='same', name='conv4')(x_conv)\n",
    "    x_conv = MaxPooling2D(pool_size=(4, 4), name='pool2')(x_conv)\n",
    "    x_conv = Dropout(config[\"dropout_2\"], name='drop2')(x_conv)\n",
    "\n",
    "    # we flatten the output\n",
    "    x_conv = Flatten()(x_conv)\n",
    "\n",
    "    # Metadata model\n",
    "    x_meta = Dense(16, activation='relu', name='metadata_fc_1')(meta_input)\n",
    "    x_meta = Dense(32, activation='relu', name='metadata_fc_2')(x_meta)\n",
    "\n",
    "    # Merged model\n",
    "    x = Concatenate(axis=1)([x_conv, x_meta])\n",
    "    x = Dense(16, activation='relu', name='comb_fc_2')(x)\n",
    "    x = Dropout(config[\"dropout_3\"])(x)\n",
    "\n",
    "    # Output (binary classification, a single sigmoid neuron giving us a score between 0 (not BTS) and 1 (BTS!!!))\n",
    "    output = Dense(1, activation='sigmoid', name='fc_out')(x)\n",
    "\n",
    "    model = keras.Model(inputs=[triplet_input, meta_input], outputs=output, name=\"mi_cnn\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, we have a model that works. But just like a baby's brain (but even worse), this thing can't do anything! It needs to be trained through trial and error, just like the scanners would. Let's spoon feed it with a ton of data so it can steal our jobs faster :)\n",
    "\n",
    "<img src=\"https://styles.redditmedia.com/t5_adbcw/styles/communityIcon_anc30b6ykk461.jpg\" alt=\"Drawing\" style=\"width: 400px;\"/>\n",
    "<p style=\"font-size: 10px;\">Source: https://www.reddit.com/r/machinelearningmemes</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model\n",
    "\n",
    "We'll start by creating a training loop, which will be used to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we add to our config some of the constants used in the training process\n",
    "config.update({\n",
    "    'batch_size': 8,\n",
    "    'epochs': 10,\n",
    "    'learning_rate': 0.001,\n",
    "    'loss': 'binary_crossentropy',\n",
    "    'optimizer': 'adam',\n",
    "    'random_seed': 42,\n",
    "    'train_data_version': \"ZTFSS\",\n",
    "    'early_stopping_patience': 10,\n",
    "    'LR_plateau_patience': 20,\n",
    "    'reduce_LR_factor': 0.5,\n",
    "    'reduce_LR_minLR': 1e-6, \n",
    "    'beta_1': 0.9,\n",
    "    'beta_2': 0.999,\n",
    "    'metadata_cols': [\n",
    "      \"sgscore1\",\n",
    "      \"distpsnr1\",\n",
    "      \"sgscore2\",\n",
    "      \"distpsnr2\",\n",
    "      \"fwhm\",\n",
    "      \"magpsf\",\n",
    "      \"sigmapsf\",\n",
    "      \"ra\",\n",
    "      \"dec\",\n",
    "      \"diffmaglim\",\n",
    "      \"ndethist\",\n",
    "      \"nmtchps\",\n",
    "      \"age\",\n",
    "      \"peakmag_so_far\"\n",
    "    ],\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "tf.keras.utils.set_random_seed(config[\"random_seed\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Loading the data:\n",
    "For this session, the dataset is already prepared and stored for you to use. It is composed of N alerts, each with 3 cutouts (science, template, difference) and 14 metadata features (2 of these features have been computed by us based on the alert history for a given object, and do not come with the basic alert packet). The training set is used to train the model, the validation set is used to evaluate the model during training.\n",
    "\n",
    "Later (after the training), we'll use the test set to evaluate the model on data it has never seen before. This is important to make sure the model is not overfitting the training data, and that it can generalize to new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 7770 candidates, 7770 triplets\n",
      "Validation set: 2589 candidates, 2589 triplets\n"
     ]
    }
   ],
   "source": [
    "cand = pd.read_csv(f'data/train_cand_{config[\"train_data_version\"]}.csv')\n",
    "triplets = np.load(f'data/train_triplets_{config[\"train_data_version\"]}.npy', mmap_mode='r+')\n",
    "\n",
    "# split the data into training and validation sets\n",
    "val_indexes = np.random.choice(cand.index, size=int(len(cand) * 0.25), replace=False)\n",
    "train_indexes = np.array(list(set(cand.index) - set(val_indexes)))\n",
    "\n",
    "val_cand = cand.loc[val_indexes]\n",
    "val_triplets = triplets[np.isin(cand.index, val_indexes)]\n",
    "\n",
    "triplets = triplets[np.isin(cand.index, train_indexes)]\n",
    "cand = cand.loc[train_indexes]\n",
    "\n",
    "# print the shape of everything\n",
    "print(f\"Training set: {cand.shape[0]} candidates, {triplets.shape[0]} triplets\")\n",
    "print(f\"Validation set: {val_cand.shape[0]} candidates, {val_triplets.shape[0]} triplets\")\n",
    "\n",
    "gen_cols = np.append(config['metadata_cols'], ['label'])\n",
    "\n",
    "x_train, y_train = triplets, cand['label']\n",
    "x_val, y_val = val_triplets, val_cand['label']\n",
    "\n",
    "# train_df is a combination of the desired metadata cols and y_train (labels)\n",
    "# we provide the model a custom generator function to separate these as necessary\n",
    "train_df = cand[gen_cols]\n",
    "val_df = val_cand[gen_cols]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we prepare the data a little further for the training loop. We'll use the tf.keras.preprocessing.image.ImageDataGenerator to perform some data augmentation, which will help the model generalize better.\n",
    "\n",
    "Also, we will weight the classes to account for the class imbalance. The weight of each class is the inverse of the class frequency in the training set, in case we have more BTS than non-BTS objects, or the opposite. This will help the model learn to classify both classes equally well, and reduce the false positives and false negatives rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator()\n",
    "val_datagen = tf.keras.preprocessing.image.ImageDataGenerator()\n",
    "\n",
    "t_generator = train_datagen.flow(x_train, train_df, batch_size=config[\"batch_size\"], seed=config[\"random_seed\"], shuffle=False)\n",
    "v_generator = val_datagen.flow(x_val, val_df, batch_size=config[\"batch_size\"], seed=config[\"random_seed\"], shuffle=False)\n",
    "\n",
    "def multiinput_train_generator():\n",
    "    while True:\n",
    "        # get the data from the generator\n",
    "        # data is [[img], [metadata and labels]]\n",
    "        # yields batch_size number of entries\n",
    "        data = t_generator.next()\n",
    "\n",
    "        imgs = data[0]\n",
    "        cols = data[1][:,:-1]\n",
    "        targets = data[1][:,-1:]\n",
    "\n",
    "        yield [imgs, cols], targets\n",
    "\n",
    "def multiinput_val_generator():\n",
    "    while True:\n",
    "        data = v_generator.next()\n",
    "\n",
    "        imgs = data[0]\n",
    "        cols = data[1][:,:-1]\n",
    "        targets = data[1][:,-1:]\n",
    "\n",
    "        yield [imgs, cols], targets\n",
    "\n",
    "training_generator = multiinput_train_generator()\n",
    "validation_generator = multiinput_val_generator()\n",
    "\n",
    "# weight data on number of ALERTS per class\n",
    "num_training_examples_per_class = np.array([np.sum(cand['label'] == 0), np.sum(cand['label'] == 1)])\n",
    "\n",
    "# fewer examples -> larger weight\n",
    "weights = (1 / num_training_examples_per_class) / np.linalg.norm((1 / num_training_examples_per_class))\n",
    "normalized_weight = weights / np.max(weights)\n",
    "\n",
    "class_weight = {i: w for i, w in enumerate(normalized_weight)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of training our model for a fixed number of epochs, we'll use early stopping. This means that the model will train until it stops improving, and then stop. This is done by monitoring the validation loss, and stopping the training if it doesn't improve for a set number of epochs (patience).\n",
    "Also, to keep training further once we plateau, we'll use a learning rate scheduler. This will reduce the learning rate by a factor of N (dividing it) once the validation loss stops improving for a set number of epochs (patience).\n",
    "\n",
    "You might have seen in the config earlier that we still specify a number of epochs. You can see this as a maximum number of epochs, which will be reached if the model doesn't stop training before with early stopping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we set some rules to stop the training process early if the validation loss does not improve\n",
    "# halt training if no improvement in validation loss over patience epochs\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    verbose=1, \n",
    "    patience=config['early_stopping_patience']\n",
    ")\n",
    "\n",
    "# reduce learning rate if no improvement in validation loss over patience epochs\n",
    "LR_plateau = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\", \n",
    "    patience=config['LR_plateau_patience'],\n",
    "    factor=config['reduce_LR_factor'],\n",
    "    min_lr=config['reduce_LR_minLR'],\n",
    "    verbose=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use [Weights and Biases](https://wandb.ai/) to log the training metrics, and to save the model. You can create a free account on https://wandb.ai/ to log your own metrics. Later in this notebook, we'll make even better use of wandb.ai to fine-tune the model with the *sweeps* feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtheodlz\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/theodlz/projects/summerschool_ztf_2024/bts-ml-ztf-summer-school/wandb/run-20240729_145211-8zq8vnid</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/theodlz/BTSbot/runs/8zq8vnid' target=\"_blank\">trim-waterfall-172</a></strong> to <a href='https://wandb.ai/theodlz/BTSbot' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/theodlz/BTSbot' target=\"_blank\">https://wandb.ai/theodlz/BTSbot</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/theodlz/BTSbot/runs/8zq8vnid' target=\"_blank\">https://wandb.ai/theodlz/BTSbot/runs/8zq8vnid</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.init(project=\"BTSbot\")\n",
    "# Send parameters of this run to WandB\n",
    "for param in list(config):\n",
    "    wandb.config[param] = config[param]\n",
    "\n",
    "run_name = wandb.run.name\n",
    "WandBLogger = wandb.keras.WandbMetricsLogger(log_freq=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use an Adam optimizer, which is a popular optimizer for deep learning. It is an adaptive learning rate optimization algorithm that's been designed specifically for training deep neural networks. It's a little more complex than the classic Stochoastic Gradient Descent (SGD) optimizer, but it's more efficient and requires less manual tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate=config['learning_rate'], \n",
    "    beta_1=config['beta_1'],\n",
    "    beta_2=config['beta_2']\n",
    ")\n",
    "model.compile(optimizer=optimizer, loss=config['loss'], metrics=['accuracy'])\n",
    "\n",
    "#PS: If you are using tensorflow v2.11+ on M1/M2/M3 macs, you might benefit from using\n",
    "# the legacy version of the optimizer, which is: tf.keras.optimizers.legacy.Adam, instead of tf.keras.optimizers.Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now (finally!), let's train the model!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "777/777 [==============================] - 9s 12ms/step - loss: 0.6866 - accuracy: 0.6586 - val_loss: 0.6255 - val_accuracy: 0.6768 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "777/777 [==============================] - 9s 12ms/step - loss: 0.6084 - accuracy: 0.6969 - val_loss: 0.6382 - val_accuracy: 0.6346 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "777/777 [==============================] - 10s 12ms/step - loss: 0.6016 - accuracy: 0.6997 - val_loss: 0.6476 - val_accuracy: 0.6376 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "777/777 [==============================] - 10s 13ms/step - loss: 0.6184 - accuracy: 0.6834 - val_loss: 0.6973 - val_accuracy: 0.6298 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "777/777 [==============================] - 11s 14ms/step - loss: 0.6113 - accuracy: 0.6876 - val_loss: 0.6253 - val_accuracy: 0.6521 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "777/777 [==============================] - 11s 15ms/step - loss: 0.5947 - accuracy: 0.7032 - val_loss: 0.6279 - val_accuracy: 0.6483 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "777/777 [==============================] - 11s 15ms/step - loss: 0.5939 - accuracy: 0.7008 - val_loss: 0.6462 - val_accuracy: 0.6327 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "777/777 [==============================] - 11s 14ms/step - loss: 0.5925 - accuracy: 0.6995 - val_loss: 0.6410 - val_accuracy: 0.6390 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "777/777 [==============================] - 12s 15ms/step - loss: 0.6086 - accuracy: 0.6845 - val_loss: 0.6983 - val_accuracy: 0.6429 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "777/777 [==============================] - 12s 15ms/step - loss: 0.5956 - accuracy: 0.6892 - val_loss: 0.6290 - val_accuracy: 0.6516 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "h = model.fit(\n",
    "    training_generator,\n",
    "    steps_per_epoch=0.8*len(x_train) // config[\"batch_size\"],\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=(0.8*len(x_val)) // config[\"batch_size\"],\n",
    "    epochs=config[\"epochs\"],\n",
    "    verbose=1, callbacks=[early_stopping, LR_plateau, WandBLogger]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Testing-the-model\"></a>\n",
    "### Testing the model\n",
    "\n",
    "Now, we'll load some test data to evaluate the model on data it has never seen before. This is important to make sure the model is not overfitting the training data, and that it can generalize to new data. Also, it will set a baseline for us to compare the model we'll fine-tune later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "324/324 [==============================] - 2s 5ms/step\n",
      "Overall validation accuracy 64.27%\n"
     ]
    }
   ],
   "source": [
    "raw_preds = model.predict([val_triplets, val_cand.loc[:,config[\"metadata_cols\"]]], batch_size=config['batch_size'], verbose=1)\n",
    "preds = np.rint(np.transpose(raw_preds))[0].astype(int)\n",
    "labels = val_cand[\"label\"].to_numpy(dtype=int)\n",
    "\n",
    "results = preds == labels\n",
    "print(f\"Overall validation accuracy {100*np.sum(results) / len(results):.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the accuracy is not great all, though as per the training results, it looks like the model was learning from the data as the training accuracy increased, but unfortunately the validation accuracy did not. One issue you might have noticed, is that we didn't learn all that much after the second iteration, we need to fix that.\n",
    "\n",
    "**However**, accuracy isn't the only metric we should look at. There're a lot more metrics that can be used to evaluate a model, and it's important to look at them all to get a better idea of how the model is performing. For example, the accuracy can be misleading if the dataset is imbalanced (which is the case here). If we have 99% of non-BTS objects, and 1% of BTS objects, a model that always predicts non-BTS will have an accuracy of 99%, but it's not a good model. This is why we'll look can look at the confusion matrix, the precision, the recall, and the F1 score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Here is are your first set of tasks:**\n",
    "\n",
    "1. Using matplotlib or your favorite plotting library, plot the confusion matrix for the test set. Hint: You can use the [sklearn.metrics.confusion_matrix](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html) function to compute the confusion matrix, and the [sklearn.metrics.ConfusionMatrixDisplay](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.ConfusionMatrixDisplay.html) to plot it.\n",
    "2. Calculate the precision, recall, and F1 score for the test set. Hint: sklearn has some tools to help you with that :)\n",
    "3. Nowadays, it's also very common to also look at a Receiver Operating Characteristic (ROC) curve and AUC: https://developers.google.com/machine-learning/crash-course/classification/roc-and-auc. Plot the ROC curve and compute the AUC for the test set.\n",
    "\n",
    "For each of the plots and metrics you come up with, try your best to interpret the results. What do they mean? What do they tell you about the model? What can you conclude from them?\n",
    "\n",
    "----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization: Grid search using Weights and Biases Sweeps\n",
    "\n",
    "After looking at our basic model's result, we can easily imagine how it can be improved. One way to do that is to try different values for all of the hyperparemeters it uses, hoping to fine-tune their value to get the best result our of our existing model. This is called hyperparameter optimization, and it's a very common practice in machine learning. A great tool to do this automatically is a grid search, which will try all the possible combinations of hyperparameters you want to try, and return the best one. However, this can be very time consuming, and it's not always possible to try all the possible combinations. This is where Weights and Biases Sweeps comes in handy.\n",
    "\n",
    "Let's use wandb.ai to fine-tune the model with their *sweeps* feature, which works pretty much like a grid search, but smarter. We'll use Weights and Biases Sweeps to perform a grid search over the hyperparameters of the model, such as: learning rate, batch size, dropout rate, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to put all of the logic above in a function that we can call from the sweep configuration file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(config):\n",
    "    WandBLogger = wandb.keras.WandbMetricsLogger(log_freq=5)\n",
    "    loss = config['loss']\n",
    "    metadata_cols = [\n",
    "        \"sgscore1\",\n",
    "        \"distpsnr1\",\n",
    "        \"sgscore2\",\n",
    "        \"distpsnr2\",\n",
    "        \"fwhm\",\n",
    "        \"magpsf\",\n",
    "        \"sigmapsf\",\n",
    "        \"ra\",\n",
    "        \"dec\",\n",
    "        \"diffmaglim\",\n",
    "        \"ndethist\",\n",
    "        \"nmtchps\",\n",
    "        \"age\",\n",
    "        \"peakmag_so_far\"\n",
    "    ]\n",
    "    tf.keras.backend.clear_session()\n",
    "    tf.keras.utils.set_random_seed(config[\"random_seed\"])\n",
    "    \n",
    "    cand = pd.read_csv(f'data/train_cand_{config[\"train_data_version\"]}.csv')\n",
    "    triplets = np.load(f'data/train_triplets_{config[\"train_data_version\"]}.npy', mmap_mode='r+')\n",
    "    \n",
    "    # set the random seed, so we can reproduce the results\n",
    "    np.random.seed(config.get(\"random_seed\", 20240729))\n",
    "\n",
    "    # split the data into training and validation sets\n",
    "    val_indexes = np.random.choice(cand.index, size=int(len(cand) * 0.2), replace=False)\n",
    "    train_indexes = np.array(list(set(cand.index) - set(val_indexes)))\n",
    "\n",
    "    val_cand = cand.loc[val_indexes]\n",
    "    val_triplets = triplets[np.isin(cand.index, val_indexes)]\n",
    "\n",
    "    triplets = triplets[np.isin(cand.index, train_indexes)]\n",
    "    cand = cand.loc[train_indexes]\n",
    "\n",
    "    gen_cols = np.append(metadata_cols, ['label'])\n",
    "\n",
    "    x_train, y_train = triplets, cand['label']\n",
    "    x_val, y_val = val_triplets, val_cand['label']\n",
    "\n",
    "    train_df = cand[gen_cols]\n",
    "    val_df = val_cand[gen_cols]\n",
    "\n",
    "\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        verbose=1, \n",
    "        patience=config['early_stopping_patience']\n",
    "    )\n",
    "\n",
    "    LR_plateau = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor=\"val_loss\", \n",
    "        patience=config['LR_plateau_patience'],\n",
    "        factor=config['reduce_LR_factor'],\n",
    "        min_lr=config['reduce_LR_minLR'],\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    train_datagen = tf.keras.preprocessing.image.ImageDataGenerator()\n",
    "    val_datagen = tf.keras.preprocessing.image.ImageDataGenerator()\n",
    "\n",
    "    t_generator = train_datagen.flow(x_train, train_df, batch_size=config[\"batch_size\"], seed=config[\"random_seed\"], shuffle=False)\n",
    "    v_generator = val_datagen.flow(x_val, val_df, batch_size=config[\"batch_size\"], seed=config[\"random_seed\"], shuffle=False)\n",
    "\n",
    "    def multiinput_train_generator():\n",
    "        while True:\n",
    "            # get the data from the generator\n",
    "            # data is [[img], [metadata and labels]]\n",
    "            # yields batch_size number of entries\n",
    "            data = t_generator.next()\n",
    "\n",
    "            imgs = data[0]\n",
    "            cols = data[1][:,:-1]\n",
    "            targets = data[1][:,-1:]\n",
    "\n",
    "            yield [imgs, cols], targets\n",
    "\n",
    "    def multiinput_val_generator():\n",
    "        while True:\n",
    "            data = v_generator.next()\n",
    "\n",
    "            imgs = data[0]\n",
    "            cols = data[1][:,:-1]\n",
    "            targets = data[1][:,-1:]\n",
    "\n",
    "            yield [imgs, cols], targets\n",
    "\n",
    "    training_generator = multiinput_train_generator()\n",
    "    validation_generator = multiinput_val_generator()\n",
    "\n",
    "    model = BTSModel(config)\n",
    "    # you might want to replace tf.keras.optimizers.Adam with tf.keras.optimizers.legacy.Adam if you are using tensorflow v2.11+ on M1/M2/M3 macs\n",
    "    optimizer = tf.keras.optimizers.legacy.Adam(\n",
    "        learning_rate=config['learning_rate'], \n",
    "        beta_1=config['beta_1'],\n",
    "        beta_2=config['beta_2']\n",
    "    )\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
    "    \n",
    "    model.fit(\n",
    "        training_generator,\n",
    "        steps_per_epoch=0.8*len(x_train) // config[\"batch_size\"],\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=(0.8*len(x_val)) // config[\"batch_size\"],\n",
    "        #class_weight=class_weight,\n",
    "        epochs=config[\"epochs\"],\n",
    "        verbose=1, callbacks=[early_stopping, LR_plateau, WandBLogger]\n",
    "    )\n",
    "\n",
    "    raw_preds = model.predict([triplets, cand.loc[:,metadata_cols]], batch_size=config['batch_size'], verbose=1)\n",
    "    preds = np.rint(np.transpose(raw_preds))[0].astype(int)\n",
    "    labels = cand[\"label\"].to_numpy(dtype=int)\n",
    "\n",
    "    results = preds == labels\n",
    "    print(f\"Overall validation accuracy {100*np.sum(results) / len(results):.2f}%\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick wrapper around the train function so it can be called nicely by a wandb sweep agent\n",
    "def sweep_train(config=None):\n",
    "    with wandb.init(config=config) as run:\n",
    "        train(run.config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll start the grid search. No need to wait for it to finish before you can see what it is doing. You can just go to your sweep's overview page on wandb to see the progress of the grid search, and the best performing runs so far."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Before running the next cell, you need to create a sweep on wandb.ai. You can do so by clicking on the \"Sweeps\" tab, and then on \"Create new sweep\". You can use this sweep config:\n",
    "```yaml\n",
    "method: bayes\n",
    "metric:\n",
    "  goal: minimize\n",
    "  name: batch/loss\n",
    "parameters:\n",
    "  LR_plateau_patience:\n",
    "    distribution: int_uniform\n",
    "    max: 40\n",
    "    min: 10\n",
    "  batch_size:\n",
    "    distribution: int_uniform\n",
    "    max: 64\n",
    "    min: 16\n",
    "  beta_1:\n",
    "    distribution: uniform\n",
    "    max: 1.8\n",
    "    min: 0.45\n",
    "  beta_2:\n",
    "    distribution: uniform\n",
    "    max: 1.998\n",
    "    min: 0.4995\n",
    "  dropout_1:\n",
    "    distribution: uniform\n",
    "    max: 0.4\n",
    "    min: 0.15\n",
    "  dropout_2:\n",
    "    distribution: uniform\n",
    "    max: 0.4\n",
    "    min: 0.15\n",
    "  dropout_3:\n",
    "    distribution: uniform\n",
    "    max: 0.4\n",
    "    min: 0.15\n",
    "  early_stopping_patience:\n",
    "    distribution: int_uniform\n",
    "    max: 15\n",
    "    min: 5\n",
    "  epochs:\n",
    "    distribution: int_uniform\n",
    "    max: 20\n",
    "    min: 5\n",
    "  learning_rate:\n",
    "    distribution: uniform\n",
    "    max: 0.002\n",
    "    min: 0.0005\n",
    "  loss:\n",
    "    distribution: categorical\n",
    "    values:\n",
    "      - binary_crossentropy\n",
    "  optimizer:\n",
    "    distribution: categorical\n",
    "    values:\n",
    "      - adam\n",
    "  random_seed:\n",
    "    distribution: categorical\n",
    "    values: \n",
    "     - 42\n",
    "  reduce_LR_factor:\n",
    "    distribution: uniform\n",
    "    max: 1\n",
    "    min: 0.25\n",
    "  reduce_LR_minLR:\n",
    "    distribution: uniform\n",
    "    max: 2e-06\n",
    "    min: 5e-07\n",
    "  train_data_version:\n",
    "    distribution: categorical\n",
    "    values:\n",
    "      - ZTFSS\n",
    "  image_size:\n",
    "    distribution: categorical\n",
    "    values:\n",
    "      - (63,63,3)\n",
    "  metadata_size:\n",
    "    distribution: categorical\n",
    "    values:\n",
    "      - (14,)\n",
    "program: train.py\n",
    "```\n",
    "\n",
    "and replace the sweep_id in the cell below with the one you get from wandb.ai.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a sweep on WandB by going to the project page and clicking \"Sweep\"\n",
    "sweep_id = None #replace with your sweep id here\n",
    "if not sweep_id:\n",
    "    raise Exception(\"Please provide a sweep id\")\n",
    "wandb.agent(sweep_id=sweep_id, function=sweep_train, count=10, project=\"BTSbot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*PS: You might see that often, the loss is `nan`. This is simply because the parameters used by that particular sweep yield very bad results, which get the model to diverge. This is why it's important to have a large number of runs in the sweep, to make sure we don't miss the best hyperparameters because of a few bad runs. But also, create new sweeps with tighter constraints for some of the hyperparameters.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "##### We'd like you to try and beat the best score we've got so far! \n",
    "\n",
    "Here's what you can do:\n",
    "\n",
    "**Go back to regular training (without any sweeps with wandb, just regular training)**\n",
    "\n",
    "1. Try different loss functions and optimizers, and/or improve on how the initial weights are initialized.\n",
    "\n",
    "2. Perform data augmentation on the cutouts, and use the augmented data to train the model. You can use the tf.keras.preprocessing.image.ImageDataGenerator (which you'll find in the code above already) to do this. You could also do the same for the metadata, but it's a little more complicated.\n",
    "\n",
    "3. Play with the model's architecture. You can add, remove, or modify the layers as you wish. You could also try to use a different CNN architecture, such as ResNet, EfficientNet, etc.\n",
    "\n",
    "4. Change the features used in the metadata model. You can add, remove, or modify the features used. You could also compute new features from the existing ones.\n",
    "\n",
    "5. Create a new clean sweep on wandb.ai, with the configuration of your choice, adding, modifying, or removing hyperparameters as you wish. You might want to increase the worker count to cover more of the parameter space.\n",
    "\n",
    "6. Improve time needed for inference. You can try to reduce the number of parameters in the model, or use a more efficient CNN architecture to make it more efficient. This is *key* for the model to be used in production, as we expect it to run on thousands of alerts every day.\n",
    "\n",
    "7. Be creative! There are an infinite number of ways to improve a model, and we're sure you can come up with something we haven't thought of :)\n",
    "\n",
    "**Once you have a model you are happy with, you should use the code you wrote in the [Testing the model](#Testing-the-model) section to evaluate it on the test set, and plot some of the metrics.**\n",
    "\n",
    "----"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
